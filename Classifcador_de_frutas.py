# -*- coding: utf-8 -*-
"""PSI_PROVA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q5U__r_df-I5yFl2h3d6XXPFPL5FqcVs
"""

import cv2 as cv
import matplotlib.pyplot as plt
import numpy as np
from os import walk
from os import listdir
import csv

drive = "drive//MyDrive//frutasdb//"   

imgs = []                                                                  
for (dirpath, dirnames, filenames) in walk(drive):
  imgs.extend(filenames)

imgs.sort()
print(imgs)
list_img = []
for i in range(len(imgs)):
    list_img.append([imgs[i], cv.imread(drive + imgs[i], 0)])
    kernel = np.ones((3,3),np.uint8)    
    list_img[i][1] = cv.morphologyEx(list_img[i][1], cv.MORPH_OPEN, kernel, iterations = 2)
    mask = np.ones((6,6),np.float32)*1/9
    list_img[i][1] = cv.filter2D(list_img[i][1],-1,mask)
    list_img[i][1] = cv.resize(list_img[i][1], (30, 30), interpolation = cv.INTER_AREA)
    contorno, ordem = cv.findContours(list_img[i][1], cv.RETR_TREE, cv.CHAIN_APPROX_NONE)
    #diametro
    diametro = np.sqrt(4*cv.contourArea(contorno[0])/np.pi )
    list_img[i].append(diametro)                               
    perimetro = cv.arcLength(contorno[0], True)
    list_img[i].append(perimetro)
    # Área
    area = cv.countNonZero(list_img[i][1])
    list_img[i].append(area)
    # Compacidade
    compacidade = np.square(perimetro)/area
    list_img[i].append(compacidade)
     #excentricidade
    (x,y), (eixoMenor,eixoMaior),angulo = cv.fitEllipse(contorno[0])
    excentricidade = (eixoMaior/eixoMenor)                                     
    list_img[i].append(excentricidade)
    #retangularidade
    retangularidade = area/(eixoMaior*eixoMenor)
    list_img[i].append(retangularidade) 
    #label                                                   
    if( i<= 30):
        list_img[i].append('Maca')
    elif(i <= 60):
        list_img[i].append('abacaxi')
    elif(i<= 90):
        list_img[i].append('banana')
    elif(i<= 120):
        list_img[i].append('peseego')
    elif(i <= 150):
        list_img[i].append('pitanga')
    elif(i <= 180):
        list_img[i].append('laranja')
    elif(i <= 210):
        list_img[i].append('morango')
    elif(i <= 240):
        list_img[i].append('pera')
    elif(i <= 270):
        list_img[i].append('limao')
    elif(i <= 300):
        list_img[i].append('uva')
    

 


csv_list = []
for i in range(len(list_img)):
    csv_list.append([list_img[i][2], list_img[i][3],list_img[i][4],list_img[i][5], list_img[i][6], list_img[i][7], list_img[i][8]]) 

with open('img_data.csv', 'w') as myfile:                                     #gera um arquivo em formato csv para armazenar os dados gerados
    wr = csv.writer(myfile, dialect='excel')
    wr.writerow(['Diametro','Perimetro', 'Area', 'Compacidade', 'excentricidade',  'retangularidade','label'])
    i = 0
    while i < len(csv_list):
      wr.writerow(csv_list[i])
      i = i + 1 

#plotando pra saber se está lendo corretamente as imagens
# print(len(imgs))
# plt.figure(figsize=(10,10))
# plt.subplot(121), plt.imshow(list_img[0][1],cmap='binary')
# plt.subplot(122), plt.imshow(list_img[-1][1],cmap='binary')
# plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn import linear_model, datasets


# # carregar o arquivo com as características
df = pd.read_csv('img_data.csv', sep=',')
df.describe()

#print(df)

# # # separar as características e os rótulos
X = df.iloc[:,0:6]    # características
y = df.iloc[:,6]      # rótulos
# print(y)
# print(X)

# #
# # PRÉ-PROCESSAMENTO
# #
normalizar = StandardScaler()
normalizar.fit(X)
X = normalizar.transform(X)
#print(X)

# #
# # PROCESSAMENTO
# # Dividir o conjunto de dados em treinamento (TRAIN) e teste (TEST)
# #
XTrain, XTest, yTrain, yTest = train_test_split(X,y,test_size=0.40, random_state=35)

# # #
# # # CLASSIFICADOR
# # #
knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(XTrain, yTrain)
Y = knn.predict(XTest)

# # #
# # # RESULTADO
# # #
acc = accuracy_score(yTest, Y)
print('Acurácia: {0:.2f}\n\n'.format(acc))

# # # Matriz confusão
print(pd.crosstab(yTest,Y,rownames=['True'],colnames=['Predição'],margins=True))

